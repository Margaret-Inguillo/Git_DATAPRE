{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import gensim\n",
    "import nltk\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora, models\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('C:/Users/Margaret/Documents/Python Scripts/cnn1.json')\n",
    "json_data = json.load(json_file)\n",
    "documents = pd.DataFrame(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>article_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9:04 p.m. ET, June 25, 2020</td>\n",
       "      <td>What you need to know</td>\n",
       "      <td>People should still be washing their hands and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8:58 p.m. ET, June 25, 2020</td>\n",
       "      <td>People should still be washing their hands and...</td>\n",
       "      <td>Some of the biggest risk factors in catching C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8:50 p.m. ET, June 25, 2020</td>\n",
       "      <td>Some of the biggest risk factors in catching C...</td>\n",
       "      <td>he US is \"not even close\" to doing enough to f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8:45 p.m. ET, June 25, 2020</td>\n",
       "      <td>The US is \"not even close\" to doing enough to ...</td>\n",
       "      <td>White House Coronavirus Task Force to hold fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8:35 p.m. ET, June 25, 2020</td>\n",
       "      <td>White House Coronavirus Task Force to hold fir...</td>\n",
       "      <td>35 p.m. ET, June 25, 2020Bill Gates says he ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date  \\\n",
       "0  9:04 p.m. ET, June 25, 2020   \n",
       "1  8:58 p.m. ET, June 25, 2020   \n",
       "2  8:50 p.m. ET, June 25, 2020   \n",
       "3  8:45 p.m. ET, June 25, 2020   \n",
       "4  8:35 p.m. ET, June 25, 2020   \n",
       "\n",
       "                                               title  \\\n",
       "0                              What you need to know   \n",
       "1  People should still be washing their hands and...   \n",
       "2  Some of the biggest risk factors in catching C...   \n",
       "3  The US is \"not even close\" to doing enough to ...   \n",
       "4  White House Coronavirus Task Force to hold fir...   \n",
       "\n",
       "                                        article_body  \n",
       "0  People should still be washing their hands and...  \n",
       "1  Some of the biggest risk factors in catching C...  \n",
       "2  he US is \"not even close\" to doing enough to f...  \n",
       "3  White House Coronavirus Task Force to hold fir...  \n",
       "4  35 p.m. ET, June 25, 2020Bill Gates says he ta...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    People should still be washing their hands and...\n",
       "1    Some of the biggest risk factors in catching C...\n",
       "2    he US is \"not even close\" to doing enough to f...\n",
       "3    White House Coronavirus Task Force to hold fir...\n",
       "4    35 p.m. ET, June 25, 2020Bill Gates says he ta...\n",
       "Name: article_body, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = documents['article_body']\n",
    "processed_docs.head()\n",
    "#removing URL\n",
    "#'map()'is a function will track on which part in 'documents['body']' data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatizing text/s\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    \n",
    "    #removing stopwords thru 'stemming'\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Margaret\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "#'wordnet' is a \"big dictionary\", posts all different words\n",
    "def lemmatize_stemming(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "#parts of speech = verbs \"pos = 'v'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [people, wash, hand, avoid, high, touch, surfa...\n",
       "1    [biggest, risk, factor, catch, covid, time, pl...\n",
       "2    [close, fight, pandemic, gate, saysfrom, melis...\n",
       "3    [white, house, coronavirus, task, force, hold,...\n",
       "4    [june, gate, say, talk, fauci, regular, basis,...\n",
       "Name: article_body, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = processed_docs.map(preprocess)\n",
    "processed_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : alarm\n",
      "1 : americans\n",
      "2 : answer\n",
      "3 : avoid\n",
      "4 : careful\n",
      "5 : category\n",
      "6 : cnnemergency\n",
      "7 : complications\n",
      "8 : consider\n",
      "9 : contact\n",
      "10 : coronavirus\n",
      "11 : covid\n",
      "12 : crucial\n",
      "13 : danger\n",
      "14 : decline\n",
      "15 : disease\n",
      "16 : emailshare\n",
      "17 : especially\n",
      "18 : expert\n",
      "19 : facebookshare\n"
     ]
    }
   ],
   "source": [
    "for x in range(0,20):\n",
    "    print(x,\":\", dictionary[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below = 15, no_above=0.5, keep_n=100000)\n",
    "#filter_extremes = limiting number of times of each word used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.cfs\n",
    "# word id : number times appeared across the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.dfs\n",
    "#word id : number of documents each word is appeared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], [], [], [], [], [], []]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus\n",
    "#Multi-dimensional array(row, number times that a particular word appears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "for x in corpus_tfidf:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
